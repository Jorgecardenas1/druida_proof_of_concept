{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0f63a7-f97a-480e-b021-48cc4a74fb9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, './Druida_POC/src/')\n",
    "\n",
    "import os\n",
    "\n",
    "from druida import Stack\n",
    "from druida import setup\n",
    "\n",
    "from druida.DataManager import datamanager\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0081948-9b18-40d4-9548-caa84d91f467",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (architecture): Sequential(\n",
       "    (hidden1): Linear(in_features=8, out_features=50, bias=True)\n",
       "    (activation1): ReLU()\n",
       "    (hidden2): Linear(in_features=50, out_features=8, bias=True)\n",
       "    (activation2): ReLU()\n",
       "    (hidden3): Linear(in_features=8, out_features=1, bias=True)\n",
       "    (output): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "torch.manual_seed(9)\n",
    "\n",
    "trainer = Stack.Trainer(learning_rate=0.001,batch_size=64, epochs=100,workers=0,gpu_number=0)\n",
    "\n",
    "dnn=Stack.DNN([{\"name\":\"hidden1\",\"layer\":nn.Linear(8,50), \"type\":\"hidden\", \"index\":0},\n",
    "               {\"name\":\"activation1\",\"layer\":nn.ReLU(),\"type\":\"activation\", \"index\":1},\n",
    "               {\"name\":\"hidden2\",\"layer\":nn.Linear(50,8),\"type\":\"hidden\", \"index\":2},\n",
    "               {\"name\":\"activation2\",\"layer\":nn.ReLU(),\"type\":\"activation\", \"index\":3}, \n",
    "               {\"name\":\"hidden3\",\"layer\":nn.Linear(8,1),\"type\":\"hidden\", \"index\":4},\n",
    "               {\"name\":\"output\",\"layer\":nn.Sigmoid(), \"type\":\"output\", \"index\":5}])\n",
    "\n",
    "##checking device \n",
    "dnn.device\n",
    "dnn.to(dnn.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512a4c86-90cd-41b7-adc1-bab7fdec793d",
   "metadata": {},
   "source": [
    "## Setting vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0528767-174a-438c-9043-d523f0ccb2fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18770, 800)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#file location\n",
    "Data_DIR=os.path.normpath('/GenerativeTestCode/Codigos/Training_Data/absorptionData_HybridGAN.csv')\n",
    "cwd = os.getcwd() \n",
    "\n",
    "#file loading\n",
    "CSV_Data=pd.read_csv(cwd+Data_DIR,header=0, index_col=0)\n",
    "spectra=CSV_Data.iloc[:,:800].astype(float) #selecting spectra\n",
    "spectra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dba1644d-ffe4-47be-b7a9-62eb0184451c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float\n"
     ]
    }
   ],
   "source": [
    "trainX=datamanager.VectorSet(spectra,type='float')\n",
    "\n",
    "#modeling sets devices and sends to device \n",
    "X_train=trainX.modeling(\n",
    "        {\n",
    "            \"type\":setup.inputType['vector'],\n",
    "            \"size\": (spectra.shape[0],spectra.shape[1]),\n",
    "            \"torchType\": torch.float32,\n",
    "            \"device\":dnn.device\n",
    "        }\n",
    ")     \n",
    "\n",
    "\n",
    "\n",
    "#lazzily load data\n",
    "dataset_train = TensorDataset(X_train)\n",
    "\n",
    "#manage suffer, batching etc\n",
    "trainLoader = DataLoader(dataset_train, batch_size=trainer.batch_size,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69bf765-bff0-4ed3-865f-14b7734e694f",
   "metadata": {},
   "source": [
    "## Setting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e487e528-2cb1-405f-b2e8-854baf83dc69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "\n",
    "IMAGE_DIR =os.path.normpath('/GenerativeTestCode/Codigos/Training_Data/')\n",
    "\n",
    "cwd = os.getcwd() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Crea el dataset. Usa \"dataset.imgs\" para mostrar el nombre del archivo\n",
    "training_data = datasets.ImageFolder(root=cwd+IMAGE_DIR,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.5],[0.5]) \n",
    "                           ]))\n",
    "#Crea el dataloader\n",
    "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=trainer.batch_size,\n",
    "                                         shuffle=False, num_workers=trainer.workers)\n",
    "\n",
    "\n",
    "\n",
    "#for x, y in train_dataloader:\n",
    "#    print(x)\n",
    "#    print(y)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440b4b6-a8fb-495b-ab46-331f11836558",
   "metadata": {},
   "source": [
    "## Setting the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2098db43-e26d-4240-b01a-ea9b6ea00db7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available Device:cpu\n",
      "Generator(\n",
      "  (conv1): ConvTranspose2d(800, 1024, kernel_size=(6, 6), stride=(1, 1), bias=False)\n",
      "  (conv2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): ReLU(inplace=True)\n",
      "  (conv4): ConvTranspose2d(1024, 512, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "  (conv5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv6): ReLU(inplace=True)\n",
      "  (conv7): ConvTranspose2d(512, 256, kernel_size=(6, 6), stride=(2, 2), padding=(4, 4), bias=False)\n",
      "  (conv8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv9): ReLU(inplace=True)\n",
      "  (conv10): ConvTranspose2d(256, 128, kernel_size=(6, 6), stride=(2, 2), padding=(5, 5), bias=False)\n",
      "  (conv11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv12): ReLU(inplace=True)\n",
      "  (conv13): ConvTranspose2d(128, 3, kernel_size=(6, 6), stride=(2, 2), padding=(4, 4), bias=False)\n",
      "  (conv14): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size=X_train.size()[1] #800\n",
    "generator_mapping_size=128\n",
    "output_channels=3\n",
    "\n",
    "#importante es que input_size para el generador\n",
    "#corresponde con un vector que muestrea un espacio Latente\n",
    "netG = Stack.Generator(trainer.gpu_number, input_size, generator_mapping_size, output_channels)\n",
    "\n",
    "trainer.multiGPU(netG)\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "\n",
    "netG.apply(weights_init)\n",
    "\n",
    "#Se muestra el modelo\n",
    "print(netG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af46e02-136d-4e4e-9abf-a16682b37831",
   "metadata": {},
   "source": [
    "## Setting the Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9dc971-74db-4686-8eaa-c772b64906a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_mapping_size=64\n",
    "channels=3\n",
    "netD = Stack.Discriminator(trainer.gpu_number, image_size, discriminator_mapping_size, channels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
