{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e063f02-6b5b-446e-a315-460cbb9772b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, './Druida_POC/src/')\n",
    "\n",
    "\n",
    "from druida import Stack\n",
    "from druida import setup\n",
    "from druida.DataManager import datamanager\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35494750-6295-4d6b-a9b4-d5332dbf56b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNN(\n",
       "  (architecture): Sequential(\n",
       "    (hidden1): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (activation1): ReLU()\n",
       "    (hidden2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (activation2): ReLU()\n",
       "    (hidden3): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dnn.clear()\n",
    "#dnn.pop()\n",
    "#dnn.forward()\n",
    "#dnn.layers\n",
    "\n",
    "trainer = Stack.Trainer(learning_rate=0.001,batch_size=1, epochs=5)\n",
    "\n",
    "dnn=Stack.DNN([{\"name\":\"hidden1\",\"layer\":nn.Linear(28*28, 512), \"type\":\"hidden\", \"index\":0},\n",
    "               {\"name\":\"activation1\",\"layer\":nn.ReLU(),\"type\":\"activation\", \"index\":1},\n",
    "               {\"name\":\"hidden2\",\"layer\":nn.Linear(512,512),\"type\":\"hidden\", \"index\":2},\n",
    "               {\"name\":\"activation2\",\"layer\":nn.ReLU(),\"type\":\"activation\", \"index\":3}, \n",
    "               {\"name\":\"hidden3\",\"layer\":nn.Linear(512,10),\"type\":\"hidden\", \"index\":4}])\n",
    "\n",
    "##checking device \n",
    "dnn.device\n",
    "dnn.to(dnn.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a05da80e-ba68-4087-a4f2-840cd7c8be90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#training_data = datasets.FashionMNIST(\n",
    "#    root=\"data\",\n",
    "#    train=True,\n",
    "#    download=True,\n",
    "#    transform=ToTensor(),\n",
    "#    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    "#)\n",
    "\n",
    "#test_data = datasets.FashionMNIST(\n",
    "#    root=\"data\",\n",
    "#    train=False,\n",
    "#    download=True,\n",
    "#    transform=ToTensor(),\n",
    "#    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))   \n",
    "#)\n",
    "\n",
    "#train_dataloader = DataLoader(training_data, batch_size=trainer.batch_size)\n",
    "#test_dataloader = DataLoader(test_data, batch_size=trainer.batch_size)\n",
    "\n",
    "\n",
    "#for x, y in train_dataloader:\n",
    "#    print(x.size())\n",
    "#    print(y.size())\n",
    "#    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cec1808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0667,  0.0510,  0.1608,  ...,  0.1922,  0.1451,  0.2235],\n",
      "          [-0.0275,  0.2627,  0.2471,  ...,  0.2784,  0.1529,  0.1373],\n",
      "          [ 0.2627,  0.2549,  0.2471,  ...,  0.1765,  0.2627,  0.0118],\n",
      "          ...,\n",
      "          [ 0.0745,  0.5451, -0.1529,  ...,  0.2471,  0.1373,  0.2235],\n",
      "          [ 0.1765,  0.3255,  0.1765,  ...,  0.3176,  0.1922,  0.1922],\n",
      "          [ 0.4353, -0.0980,  0.2941,  ...,  0.4039,  0.1137,  0.0902]],\n",
      "\n",
      "         [[ 0.0824,  0.0667,  0.1608,  ...,  0.0118, -0.0196,  0.0588],\n",
      "          [-0.0118,  0.2784,  0.2471,  ...,  0.0980, -0.0118, -0.0275],\n",
      "          [ 0.2784,  0.2706,  0.2471,  ...,  0.0118,  0.0980, -0.1529],\n",
      "          ...,\n",
      "          [-0.1294,  0.3412, -0.3333,  ...,  0.0353, -0.0745,  0.0118],\n",
      "          [-0.0275,  0.1216, -0.0275,  ...,  0.0902, -0.0353, -0.0353],\n",
      "          [ 0.2314, -0.3020,  0.0902,  ...,  0.1765, -0.1137, -0.1373]],\n",
      "\n",
      "         [[-0.0196, -0.0353,  0.0980,  ...,  0.0588,  0.0196,  0.0980],\n",
      "          [-0.1137,  0.1765,  0.1843,  ...,  0.1451,  0.0275,  0.0118],\n",
      "          [ 0.1765,  0.1686,  0.1843,  ...,  0.0510,  0.1373, -0.1137],\n",
      "          ...,\n",
      "          [-0.0431,  0.4275, -0.2549,  ...,  0.1529,  0.0588,  0.1451],\n",
      "          [ 0.0588,  0.2078,  0.0745,  ...,  0.2314,  0.1216,  0.1216],\n",
      "          [ 0.3176, -0.2157,  0.1922,  ...,  0.3176,  0.0431,  0.0196]]]])\n",
      "tensor([0])\n"
     ]
    }
   ],
   "source": [
    "image_size = 32\n",
    "DATA_DIR = '/data/Cactus/aerial-cactus-identification/train/'\n",
    "cwd = os.getcwd() \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Crea el dataset. Usa \"dataset.imgs\" para mostrar el nombre del archivo\n",
    "training_data = datasets.ImageFolder(root=cwd+DATA_DIR,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize([0.5],[0.5]) \n",
    "                           ]))\n",
    "#Crea el dataloader\n",
    "train_dataloader = torch.utils.data.DataLoader(training_data, batch_size=trainer.batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "for x, y in train_dataloader:\n",
    "    print(x)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5e18cb0-043b-4dbf-839d-c5910a6688b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#labels_map = {\n",
    "#    0: \"T-Shirt\",\n",
    "#    1: \"Trouser\",\n",
    "#    2: \"Pullover\",\n",
    "#    3: \"Dress\",\n",
    "#    4: \"Coat\",\n",
    "#    5: \"Sandal\",\n",
    "#    6: \"Shirt\",\n",
    "#    7: \"Sneaker\",\n",
    "#    8: \"Bag\",\n",
    "#    9: \"Ankle Boot\",\n",
    "#}\n",
    "# Display image and label.\n",
    "# train_features, train_labels = next(iter(train_dataloader))\n",
    "# print(f\"Feature batch shape: {train_features.size()}\")\n",
    "# print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "# img = train_features[0].squeeze()\n",
    "# label = train_labels[0]\n",
    "# plt.imshow(img, cmap=\"gray\")\n",
    "# plt.show()\n",
    "# print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "722598d8-82ff-4dff-b1cc-43f84db7c0f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#optimizer\n",
    "optimizer = torch.optim.Adam(dnn.parameters(), lr=trainer.learning_rate )\n",
    "#loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd31127f-895a-48d7-9ed4-c6f295befe77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Arrays to log and plot loss values\n",
    "\n",
    "\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, batch, acc,loss_val):\n",
    "    size = len(dataloader)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "\n",
    "    X,y=dataloader\n",
    "    \n",
    "    size = len(X)\n",
    "\n",
    "\n",
    "    # Compute prediction and loss\n",
    "\n",
    "    #prediction\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "        \n",
    "    running_loss = loss.item()\n",
    "    current =  (batch + 1) * len(X)\n",
    "    #print(f\"Training Loss: {loss:>7f}  [{current:>5d}/{size:>5d}] \\n\")\n",
    "    acc = (pred.argmax(1) == y).type(torch.float).mean().item()\n",
    "\n",
    "    print(f\"Training: \\n Accuracy: {100*acc}%, Loss: {loss:>7f}  [{current:>5d}/{size:>5d}] \\n\")\n",
    "    \n",
    "    return acc, running_loss\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn,batches, batch,acc_test,test_loss):\n",
    "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    num_batches = batches\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        X, y = (dataloader)\n",
    "        size = len(X)\n",
    "\n",
    "        pred = model(X)\n",
    "        test_loss = loss_fn(pred, y).item()\n",
    "        acc_test = (pred.argmax(1) == y).type(torch.float).mean().item()\n",
    "           \n",
    "    \n",
    "    #test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Accuracy: {100*(acc_test):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "    return acc_test, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94a1e932-69fa-415d-bee7-c9ec91fd2872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (28x28 and 2352x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/AIProjects/Agosto2023/./Druida_POC/src/druida/Stack.py:33\u001b[0m, in \u001b[0;36mTrainer.training\u001b[0;34m(self, trainFunction, testFunction, train_dataloader, test_dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     29\u001b[0m testdataiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(test_dataloader)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m acc,loss\u001b[38;5;241m=\u001b[39m\u001b[43mtrainFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataiter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43macc\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m acc_test,test_loss\u001b[38;5;241m=\u001b[39mtestFunction(\u001b[38;5;28mnext\u001b[39m(testdataiter), model, loss_fn,\u001b[38;5;28mlen\u001b[39m(train_dataloader), t, acc_test,test_loss)\n\u001b[1;32m     36\u001b[0m loss_values\u001b[38;5;241m.\u001b[39mappend(loss)\n",
      "Cell \u001b[0;32mIn[15], line 19\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer, batch, acc, loss_val)\u001b[0m\n\u001b[1;32m     13\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Compute prediction and loss\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m#prediction\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/AIProjects/Agosto2023/./Druida_POC/src/druida/Stack.py:86\u001b[0m, in \u001b[0;36mDNN.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m     85\u001b[0m     action\u001b[38;5;241m=\u001b[39mlayer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/AI/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (28x28 and 2352x512)"
     ]
    }
   ],
   "source": [
    "trainer.training(train_loop,test_loop, train_dataloader,test_dataloader, dnn, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8904374e-8627-4d95-b9a0-92dae79a38ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
